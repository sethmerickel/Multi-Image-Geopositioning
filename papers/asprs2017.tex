\documentclass[10pt]{amsart}
\usepackage[total={6.5in,9in}]{geometry}
%\documentclass{article}
%\usepackage{amsmath}
\usepackage{graphicx} % for png figures
\usepackage{subcaption} % for subfigures
\usepackage{xfrac} % for sfrac (slanted inline fractions)
%\usepackage{amsaddr} % addresses up front
%\usepackage{amssymb, amsmath, bm, nameref}
\pagenumbering{gobble} % no page numbers

\newcommand{\Iimg}{\mathcal{I}}
\newcommand{\Pimg}{\mathcal{P}}

\newcommand{\imgmeashat}{\pmb{\hat{x}_{i}}}
\newcommand{\imgmeas}{\pmb{x_{i}}}
\newcommand{\grndhat}{\pmb{\hat{X}}}
\newcommand{\grnd}{\pmb{X}}
\newcommand{\grnditer}{\pmb{X^k}}
\newcommand{\sensmeashat}{\pmb{\hat{p}_i}}
\newcommand{\sensmeas}{\pmb{p_i}}
\newcommand{\imgnu}{\pmb{\nu_{i}^m}}
\newcommand{\sensnu}{\pmb{\nu_i^p}}
\newcommand{\grndupdate}{\pmb{\Delta}}
\newcommand{\grndupdateiter}{\pmb{\Delta^k}}
\newcommand{\Fimgpartials}{\frac{\partial{\pmb{F_{i}}}}{\partial{\imgmeas}}}
\newcommand{\Fgrndpartials}{\frac{\partial{\pmb{F_{i}}}}{\partial{\grnd}}}
\newcommand{\Fsenspartials}{\frac{\partial{\pmb{F_{i}}}}{\partial{\sensmeas}}}
\newcommand{\btwbi}{B^T_iW_iB_i}
\newcommand{\btwbj}{B^T_jW_jB_j}

\newtheorem{theorem}{Theorem}


\begin{document}


\title[Small Geopositioning Error from Many Images]{}
%{Asymptotically Small Geopositioning Error from Large Sets of Imagery}
\author[Settergren]{}%{\bf \rm{Reuben Settergren}}
\author[Merickel]{}%{Seth Merickel}
\maketitle


\vskip -1.1in

\begin{centering}
{\large \bf ASYMPTOTICALLY SMALL GEOPOSITIONING ERROR \\ FROM LARGE SETS OF IMAGERY}

\vspace \baselineskip

{\bf Reuben Settergren}

{\bf Seth Merickel}

{\tt rjs@jhu.edu}

{\tt sethmerickel@gmail.com}

\end{centering}

\vspace \baselineskip

%\begin{abstract}
%\begin{quotation}

{\noindent \large \bf ABSTRACT}
\vspace \baselineskip

\noindent The geolocation error resulting from least-squares Multi-Image Geopositioning
(MIG) with $N$ images is shown theoretically and empirically to decrease as
$1/\sqrt{N}$, using a synthetically augmented set of 1000 overlapping
Worldview-1 images. A novel heuristic approach called `Hourglassing' is
introduced, which requires no understanding of apriori covariance, but
implicitly infers uncertainty from the distribution of the ray bundle
itself. Hourglassing geolocation and error estimation is compared to MIG using
the 1000-image testbed.
%\end{quotation}
%\end{abstract}

\section{Introduction}
Least-squares Multi-Image Geopositioning (hereafter MIG) is well-under\-stood in
photogrammetry\cite{LSQRMIG}, providing geolocation and output covariance that
are as accurate as the apriori projection and covariance data that are input
into the process. However, for practical reasons, the number of images that have
been used in MIG calculations have been rather small. Even after the advent of
computing enabled the automatic processing of many images, there still remained
the practical problem of {\em having} very many images that observed the same
ground feature (as well as meaningful apriori covariance models). A typical
airborne collection with a mapping camera and 60/40 forward/side-lap
configuration would yield at most 6 views. A collection with large satellite
images is usually designed to have minimally sufficient overlap, yielding only
1- or 2-deep coverage almost everywhere (depending on a mono or stereo collect),
with imagery being 2- or 4-deep at the overlaps only to ensure there are no gaps.

Some authors have applied MIG with more extensive collections of imagery. In
\cite{JEONG_SIX}, Jeong, Yang, and Kim analyze MIG with one pair of imagery from
each of three different satellites: IKONOS, QuickBird, and KOMPSAT-2. In
\cite{PLANE_COLLINS}, R.~T.~Collins geopositions with 7 images simultaneously
(although not with MIG, but a technique called `Space-Sweep' -- which is
similar to the Hourglassing method introduced in section \ref{hourglassing}).
In \cite{LRO_NINE}, a team from the Chinese Academy of Sciences investigates MIG
accuracy with 2--9 images of the moon from the Lunar Reconnaissance
Orbiter. Wonnacott \cite{WONNACOT_32_3} analyzes MIG accuracy with SAR, using 32
image `sets' (each set being a `three-aperture path sequence').

These image collections, however, represent only a fraction of what is currently
possible, given the ubiquity of high-resolution commercial satellite imaging
from companies like Digital Globe, Airbus, SPOT, Pl\'eiades, KOMPSAT,
COSMO-SkyMed, TerraSAR-X, etc. A search of the Digital Globe online imagery
catalog \cite{BROWSE_DG} reveals well over 100 images for many large cities. And
the current wave of SmallSat flocks (Planet Labs, RapidEye, etc.) with their
rapid revisit times, promise to provide floods of repeat imagery. Although
SmallSats may be inferior in resolution and accuracy at the moment, technology
will improve, and it is the goal of this paper to show that these deficiencies
can be overcome by the power of large amounts of statistically independent
information from huge numbers of images.

\section{Least-Squares MIG With Many Images}
\subsection{MIG Solution}\label{MIG}
We begin with a derivation of least-squares MIG. For the details of this
procedure see the discussion of the Gauss-Helmert model in \cite{LSQRMIG},
\cite{PHOTO_CV}, \cite{MANUAL}.

In general MIG can determine the locations and joint covariance of many ground
points, but here we are concerned with just one point. Also, MIG is capable of
appropriately handling known correlations, but for our purposes we assume full
independence between all images and measurements.

The goal is therefore to determine the ground location that minimizes the weighted
sum of image measurement and sensor parameter deviations using non-linear least
squares. Let $\grnd = [X, Y, Z]'$ be the apriori position of the ground point
being estimated.  $\imgmeas = [x_{i}, y_{i}]'$ is the measurement of the ground
point in the $i$th image.  The sensor parameters for the $i$th image are
$\sensmeas = [p_{i1}, p_{i2}, \ldots]'$. The ground point, image measurements,
and sensor parameters are related through the sensor's ground to image function
$\imgmeas = \pmb{g_i}(\sensmeas, \grnd)$.  Let $\pmb{F_{i}}$ be the measurement
residual function for the $i$th image, which is the difference between the
projected ground point and image measurement:
\begin{equation*}
\pmb{F_{i}}(\sensmeashat, \grndhat,\imgmeashat)=\pmb{g_i}(\sensmeashat,\grndhat)-\imgmeashat,
\end{equation*}
where $\imgmeashat$, $\sensmeashat$, and $\grndhat$ are measured quantities
related to the predicted quantities by:
\begin{equation*}
\begin{split}
\imgmeashat = \imgmeas + \imgnu\\
\sensmeashat    = \sensmeas + \sensnu\\
\grndhat    = \grnd + \grndupdate
\end{split}
\end{equation*}
$\imgnu$ and $\sensnu$ are differences in the predicted and measured image
coordinates and sensor parameters respectively.  $\grndupdate$ will be the
correction to the ground point, for which we are solving.

Taylor expanding $\pmb{F_{i}}$ about the predicted values gives
\begin{equation} \label{taylor_eq}
\pmb{F_{i}}(\sensmeashat, \grndhat, \imgmeashat) = 
\pmb{F_{i}}(\sensmeas, \grnd, \imgmeas) + \Fimgpartials\imgnu + \Fsenspartials\sensnu + \Fgrndpartials\grndupdate = 0
\end{equation}
Sensor parameter partials are denoted by $A_{i}^p = \Fsenspartials$, and the
sensor ground partials by $B_{i} = \Fgrndpartials$.  The partials with respect
to image coordinates are ${\Fimgpartials=-I_{2 \times 2}}$, the negative of the
$2 \times 2$ identity matrix.  Substituting $A_{i}$ and $B_{i}$ into
(\ref{taylor_eq}) and rearranging terms gives:
\begin{equation} \label{linear_eq}
\begin{split}
-\imgnu + A_{i}\sensnu + B_{i}\grndupdate = \imgmeas - \pmb{g_i}(\sensmeas, \grnd) = \pmb{f_{i}}
\end{split}
\end{equation}
Stacking up equations for each measurement into one vector equation gives
\begin{equation}\label{stacked_eq}
-\pmb{\nu^x} + A\pmb{\nu^p} + B\grndupdate = \pmb{f}
\end{equation}

The function to be minimized is the weighted sum of the measurement deviations
and sensor deviations given by 
$\Phi = \pmb{\nu^x}' W^x \pmb{\nu^x} + \pmb{\nu^p}' W^p \pmb{\nu^p}$ 
subject to the constraints in (\ref{stacked_eq}).
$W^x$ and $W^p$ are inverses of the measurement covariance matrix and sensor
parameter covariance matrix respectively. Minimizing $\Phi$ using Lagrange multipliers 
to account for the constraint specified in (\ref{stacked_eq}) results in the following normal equations:
\begin{equation} \label{normal_eq}
B' W B\pmb{\Delta} = B' W \pmb{f}
\end{equation}
where $W$ is the sensor parameter and image measurement error combined into a single weight matrix:
\begin{equation}\label{weight_eq}
W = ({W^x}^{-1} + A {W^p}^{-1} {A}')^{-1}
\end{equation}

This linear system can be solved for $\Delta$, which is used to correct the
ground estimate $\grnd$. To the extent that partial derivative matrices $A$
and $B$ evaluated at $\grnd$ vs $\grnd+\Delta$, this is a non-linear
problem, so iteration is used to converge to a solution.  After each iteration
the ground point locations from the previous iteration are updated $\pmb{X^k} =
\pmb{X^{k - 1}} + \pmb{\Delta^k}$, and the partial derivative matrices $A$ and
$B$ are evaluated at the new ground point location for the next iteration.
Convergence is typically achieved after only a few iterations. (However for the
experiments in section \ref{simulation}, the partial derivatives were so stable,
only one iteration was necessary; the 2nd iteration yielded only negligible
correction.)

\subsection{MIG Covariance}
From the normal equations (\ref{normal_eq}) it is straightforward to show that
the covariance of the ground point estimate is:
\begin{equation} \label{covariance_eq}
C^g = (B'WB)^{-1}
\end{equation}

To understand how $C^g$ depends on the number of images, we establish and upper
bound on $C^g$ and show that the variance of each component decays as $1/N$
where $N$ is the number of images.  As a metric for comparing covariance
matrices, we use the volume of the standard ellipsoid $(X - \bar{X})'C^g(X -
\bar{X}) = 1$.  Note that we do not need to differentiate between
identically-sized ellipsoids that differ only by rotation.  The volume of an
ellipsoid is $\sfrac{\pi}{4}\cdot abc$, where $a$, $b$, and $c$ are the lengths of the three
axes of the ellipsoid, which are the eigenvalues $\lambda_1$, $\lambda_2$, and
$\lambda_3$ of the covariance matrix (We use the convention $\lambda_1 \le
\lambda_2 \le \lambda_3$, and since covariance matrices are positive definite,
$\lambda_1 > 0$).  Using the fact that the determinant of a positive definite
matrix is the product of its eigenvalues we define: $C_1 \ge C_2 \leftrightarrow
|C_1| \ge |C_2|$

Using (\ref{covariance_eq}), and the properties of the determinant, we have $|C|
= |B'WB|^{-1}$. Since we want an upper bound on $|C|$, we need to demonstrate a
lower bound for $|B'WB|$. Recall the initial assumption of independence of all
image measurements, and sensor parameters for different images.  This means the image
measurement covariance matrix $C^m$ and sensor parameter covariance matrix $C^p$
are block diagonal. Thus we have:
\begin{eqnarray}\label{btwb_eq}
B'WB & = & \sum_{i}B'_i(C^m_i + A_iC^p_iA'_i)^{-1}B_i \nonumber \\
     & = & \sum_{i}B'_iW_iB_i
\end{eqnarray}
%
where $W_i = (C^m_i + A_iC^p_iA^T_i)^{-1}$.

If $A$ is an $n\times n$ matrix then let $\lambda_i(A)$ be the $i$th smallest
eigenvalue of $A$.  In (\ref{btwb_eq}) each image contributes a term of $\btwbi$
to the sum. Because $W_i$ is $2\times 2$ and $B_i$ is $2\times 3$, each $\btwbi$
is $3\times 3$ and, only rank 2. The two eigenvectors of $\btwbi$ with nonzero
eigenvalues are the rows of $B_i$ (the ground-space projections of the line and
sample directions in image space), and the eigenvector corresponding to the
eigenvalue $\lambda_1(\btwbi)=0$ is their cross-product, the line of sight ray
projecting from the image measurement.

Assume two images and measurements $i$ and $j$ such that the rays from those
measurements are identical/parallel. Call that vector $l$. Then
%
\begin{eqnarray*}
l'(\btwbi+\btwbj)l & = & l'\btwbi l + l'\btwbj l \\
                   & = & 0 + 0
\end{eqnarray*}
Thus $l$ is also a trivial eigenvector of $\btwbi+\btwbj$, and $\lambda_1(\btwbi+\btwbj)=0$.

However, since in reality no two images will be collected with perfectly
parallel image rays, we can safely assume that for all $i\ne j\in 1\ldots n$,
$\lambda_1(\btwbi+\btwbj)>0$. Let 
\begin{equation}\label{w_assumption_eq}
\delta = \min_{i\ne j}\lambda_1(\btwbi+\btwbj) > 0
\end{equation}

Horn and Johnson in \cite{H_AND_J} give a useful property of eigenvalues of positive semidefinite
matrices $A$ and $B$: for $l\le k,
\lambda_{k-l+1}(A)+\lambda_l(B)<=\lambda_k(A+B)$.
In particular, for $k=l=1$,
\begin{equation}\label{HJ_4_3_1}
\lambda_1(\btwbi)+\lambda_1(\btwbj) \le \lambda_1(\btwbi+\btwbj)
\end{equation}
%
Using (\ref{HJ_4_3_1}), we can prove the following theorem:

\begin{theorem} \label{theorem_1}
	 For $\delta > 0$ if $\lambda_1(B^T_iW_iB_i + B^T_jW_jB_j) \geq \delta$
         for all $i, j = 1, \dots, n$ $i \ne j$ then $\lambda_1(\sum_i
         B^T_iW_iB_i) \geq \frac{n\delta}{2}$ for $n$ even and
         $\frac{(n-1)\delta}{2}$ for $n$ odd
\end{theorem}

This can be proven using induction.  We will outline the proof for even
$n$ starting with the following motivation:

\begin{equation*}
\begin{aligned}
&\lambda_1(B^T_1W_1B_1 + B^T_2W_2B_2) \geq \delta \rightarrow \frac{n\delta}{2} \text{, with } n = 2\\
&\lambda_1(B^T_1W_1B_1 + B^T_2W_2B_2 + B^T_3W_2B_3) \geq \lambda_1(B^T_1W_2B_1 + B^T_2W_2B_2) + \lambda_1(B^T_3W_3B_3) \geq
\delta + 0 \rightarrow \frac{(n-1)\delta}{2} \text{, with } n = 3\\
&\lambda_1(B^T_1W_1B_1 + B^T_2W_2B_2 + B^T_3W_3B_3 + B^T_4W_4B_4) \geq \lambda_1(B^T_1W_2B_1 + B^T_2W_2B_2) + \lambda_1(B^T_3W_3B_3 + B^T_4W_4B_4) \geq
\delta + \delta \rightarrow \frac{n\delta}{2} \text{, with } n = 4\\
\end{aligned}
\end{equation*}

\begin{equation*}
\vdots
\end{equation*}

The pattern above suggests that the theorem is correct.  To make the argument more 
formal notice that $\lambda_1(B^T_1W_1B_1 + B^T_2W_2B_2) \geq \delta$ by
definition.  Assume $\lambda_1(\sum^k_i B^T_iW_iB_i) \geq \frac{k\delta}{2}$ for
all even $k < n$ and $\lambda_1(\sum^k_i B^T_iW_iB_i) \geq
\frac{(k-1)\delta}{2}$ for all odd $k < n$.  Then
\begin{eqnarray*}
\lambda_1(\sum^n_iB^T_iW_iB_i) &=&\lambda_1(\sum^{n-2}_i B^T_iW_iB_i + B^T_{n-1}W_{n-1}B_{n-1} +  B^T_{n}W_{n}B_{n})\\
&\geq&\lambda_1(\sum^{n-2}_i B^T_iW_iB_i) +  \lambda_1(B^T_{n-1}W_{n-1}B_{n-1} + B^T_{n}W_{n}B_{n})\\
&\geq&\frac{(n-2)\delta}{2} + \delta = \frac{n\delta}{2}
\end{eqnarray*}

The first inequality follows from (\ref{HJ_4_3_1}) and the second
inequality follows from the induction hypothesis. $\qed$


Our goal is to find a covariance matrix $U(N)$, where $N$ is the number of images, which is an upper bound on the 
estimated ground point covariance $C^g$ and show that the variance (diagonals) of
$U(N)$ decrease as $1/N$. Once we determine $U(N)$ we can conclude that the variances
in $C^g$ will decrease at least as fast as $1/N$.  We begin with $\delta$ defined by (\ref{w_assumption_eq})
and use the previous theorem (\ref{theorem_1}) to state $\lambda_1(\sum_i^NB_i^TW_iB_i) \geq \frac{N\delta}{2}$.  
Next, define the matrix $M(N) = \frac{(N-1)\delta}{2}I_{3 \times 3}$,
where $I_{3\times 3}$ is the $3 \times 3$ identity matrix.
We will see that the upper bound $U(N)$ we are looking for is $M(N)^{-1}$.
The eigenvalues of $M(N)$ are all equal to $\frac{(N-1)\delta}{2}$,
which are all less than or equal to the smallest eigenvalue of $\sum^N_i B'_iW_iB_i$ by theorem \ref{theorem_1}.
This implies that the product of the eigenvalues of $B^TWB$ is larger than the product
of the eigenvalues of $M(N)$ which equals $(\frac{(N - 1)\delta}{2})^3$.  It follows that
$|B^TWB| \geq |M(N)|$ or $|(B^TWB)^{-1}| \leq |M(N)^{-1}|$, using the fact that
the matrices are positive definite so the determinants are positive. Finally, we see that
$U(N) = M(N)^{-1} = \frac{2}{(N-1)\delta}I_{3\times 3}$ is an upper bound on the 
ground point estimate covariance $C^g$ and that the variances (diagonals) of $U(N)$ 
decrease as $1/N$.  We conclude that the variances of $C^g$ must also decrease at 
least as $1/N$.

\subsection{\label{simulation}Simulation with Synthetic Imagery}
In this section we construct a large testbed of simulated/\-syn\-the\-tic imagery, and
evaluate the accuracy of MIG geolocation and error estimation, on samples of
randomly-selected subsets of images, of size ranging from 4 to 1000.

To develop the test set, we start with a large as possible set of real sensor
models which have common overlap. (Note `sensor models', not `images.' For
this simulated experiment, no pixels are needed, only sensor models. Actual
scene content is irrelevant.)  From \cite{MIN} we have sensor models from 10
Worldview-1 images which all view the ground location 36N 117.5W 1700mHAE
(WGS84). This point is set as Ground Truth. (The sensor model used in this study
is the SOCET GXP \cite{SGXP} Worldview sensor model.) We then synthetically
extend the set of real sensor models by randomly perturbing position and
orientation adjustable parameters with very large corrections. Using this random
perturbation technique, we generate 99 perturbations for each of the 10
original images, for a total of 1000 sensor models.

The simulated set of 1000 images thus constructed is considered the Truth set of
sensor models. The sensor model's ground to image function is used to project
the truth point into image coordinates for each sensor model. These image
measurements are retained as truth also, and used for all the following
experimental ray-intersections. The ray bundle emanating from these truth image
points intersect perfectly (to within computational precision of the image to
ground function) at the truth point in ground space. Let this idealized set of
images and measurements be $\Iimg$.

Once the ideal bundle $\Iimg$ is assembled, an image bundle with realistic
errors can be constructed by perturbing sensor model parameters from $\Iimg$ with a
controlled amount of error (randomly sampled from a known distribution), to
obtain perturbed image set $\Pimg$. Nine position/velocity/ac\-cel\-eration
parametrs are given $\sigma = 1{\mathrm m}, 0.1{\mathrm m}/{\mathrm s},
0.01{\mathrm m}^2/{\mathrm s}^2$, and 9 attitude/rate/acceleration parameters
are given
$\sigma=5\mu\mathrm{rad}, \sigma=0.5\mu\mathrm{rad}, \sigma=0.05\mu\mathrm{rad}$.
This model yields a CE90 of about 6-8m for the original 10 images, depending
on obliquity. Any subset of images of $\Pimg$ (along with the truth measurements
on those images) can be used as a realistic input to least-squares MIG. Apriori
covariance input to the MIG is the same error model that was used to perturb
$\Iimg$ into $\Pimg$.

Let $\Pimg$ be the set of 1000 perturbed images. For each
$N\in\{4,5,...$ $100,105,...995\}$, we randomly sample $k=100$ subsets of size
$N$ images from $\Pimg$. Least-squares MIG is used to estimate the geolocation
of the truth point using each $N$-image subset. Because we know the truth ground
point, the trivial intersection of $\Iimg$, we can compute the actual error of
each of these MIGs, and observe the distribution of error as $N$ increases.

\begin{figure}
\includegraphics[width=.7\textwidth]{fig_refvar.png}
\caption{\label{fig:vanillaref}All reference variances. For every $N$, each of
  the $k=100$ MIG generates one pixel in the graph.}
\end{figure}

\begin{figure}
\includegraphics[width=.7\textwidth]{fig_avgxyz.png}
\caption{\label{fig:vanillaxyz}Average Errors in X, Y, and Z. The horizontal
  lines represent the MIG solution for all $N=1000$ images of $\Pimg$: (-0.0049,
  -0.0330, 0.0378), to which the subset MIGs converge.}
\end{figure}

\begin{figure}
\includegraphics[width=.7\textwidth]{fig_pred_meas.png}
\caption{\label{fig:vanilla_pred_meas}Predicted vs measured CE90/LE90 (log
  scale). Measured values are adjusted with a finite population correction.}
\end{figure}

\begin{figure}
\includegraphics[width=.7\textwidth]{fig_pred_meas_sqrtn.png}
\caption{\label{fig:vanilla_pred_meas_sqrtn}Predicted vs measured CE90/LE90,
  scaled by $\sqrt{N}$.}
\end{figure}

Figure \ref{fig:vanillaref} shows the reference variances of every MIG from this
experiment (a total of 27600 individual MIG calculations). Reference variance is
tightly clustered around 1, which demonstrates that the use of apriori
covariance in the MIG calculations is consistent with the errors involved in the
perturbation of $\Pimg$.

Figure \ref{fig:vanillaxyz} shows the average of MIG errors in the X, Y, and Z
dimensions. Each point represents an average over $k=100$ MIGs. Because errors
in positive and negative directions cancel each other out, this graph shows the
amount of bias in the MIG calculations across $N$-subsets. For all $N=1000$
images of $\Pimg$, the MIG solution differs from ground truth by (-0.0049,
-0.0330, 0.0378) meters. Horizontal lines at those values indicate that as
$N\rightarrow 1000$, bias across the $k=100$ MIGs for each $N$ converges to that
error inherent to $\Pimg$.

To avoid positive and negative errors canceling each other out, we switch to
positive quantities. Figure \ref{fig:vanilla_pred_meas}a shows the average
predicted and measured CE90/LE90 for each $N$ across the $k=100$ MIGs for that
$N$. To clarify the rate of convergence and separation of the curves, a
logarithmic scale is used. (The measured errors are adjusted with a finite
population correction of $\sqrt{(1000-N)/(1000-1)}$ \cite{FPC}. The deviation of
the measured errors from prediction near 1000 is believed to be due to
limitations of the finite population correction when applied to a 90\% statistic
rather than a 1-sigma standard deviation)

In order to demonstrate the $1/\sqrt{N}$ behavior of MIG error, Figure
\ref{fig:vanilla_pred_meas}b scales each point from Figure
\ref{fig:vanilla_pred_meas}a by a factor of $\sqrt N$. The flatness of these
curves demonstrates the thesis of this paper, that MIG follows the Law of Large
Numbers, and exhibits error that decreases as $1/\sqrt N$.




\section{Hourglassing\label{hourglassing}}
\subsection{Motivation}
Because commonly-available sensor models (such as RPC) often lack a meaningful
error model to input to MIG, and for computational simplicity, we introduce a
heuristic approach as an alternative to rigorous least-squares MIG. Although
when visualized 'up close' to the true answer, any particular tangle of rays may
seem unclear about where the ground point should be localized, from a distant
perspective, the ray bundle will be something like a cone, widening to the
cluster of satellite (or airborne) perspective centers, narrowing at the ground
point, and widening again beyond the ground point. We seek the answer at the
narrowest point of the cone. In an ideal case, the ray bundle will intersect at
a single point, which has cross-sectional area of 0. In a real-world case, the
bundle will appear as a cone with a `fat' intersection, or an hourglass. Thus
the name `hourglassing' to motivate the heuristic technique.

In `plane-sweep stereo' \cite{PLANE_SWEEP}, a plane is swept through a ground
scene to find stereo focus depth, where conjugate rays are closest. The
technique is expanded for multi-view 3D scene reconstruction in
\cite{PLANE_COLLINS}. We adopt a similar approach here. Given a bundle of rays,
we can intersect the bundle with planes of various heights, compute the
collection of intersections of the ray bundle with each height plane, measure
the spread of the 2-D distribution of points, and choose the plane with the
least spread to be the solution for the height of the desired ground point. For
the horizontal location of the ground point, the natural choice is the mean of
the intersection points in the optimal (spread-minimizing) plane.

Rather than attacking this problem with a brute force search for the
spread-minimizing height by computing intersection sets at very many heights,
and slicing height space sufficiently thin to achieve a desired vertical
resolution, we attempt some theoretical underpinnings for this technique that
will allow a more efficient and precise solution.

\subsection{Computing height of minimum spread\label{poly}}
Assume two heights $z_{+} > z_{-}$, and assume a set of $N$ 3D lines $L_i$, none
of which is horizontal (without loss of generality, we use horizontal planes. If
necessary, the ray bundle can be rotated into a coordinate system so that the
`center' of the ray bundle is vertical). Specify the lines by their
intersections with the planes of heights $z_\pm$ at points
$(x_{+}^{i},y_{+}^{i}, z_+)$ and $(x_{-}^{i},y_{-}^{i}, z_-)$, for $i=1\ldots
N$.

Define
$$x^i(\lambda) = \lambda x^i_+ + (1-\lambda) x^i_-$$
$$y^i(\lambda) = \lambda y^i_+ + (1-\lambda) y^i_-$$
$$z(\lambda) = \lambda z_+ + (1-\lambda) z_-$$ For any $\lambda$,
$(x^i(\lambda), y^i(\lambda), z(\lambda))$ is a point on line $L_i$. Whether the
point is an interpolation between or extrapolation beyond the $z_\pm$ planes
depends on whether $0\le\lambda\le 1$ (in either case, we will just use the term
interpolated). Together, all the points $(x^i(\lambda), y^i(\lambda),
z(\lambda))$ for $i=1\ldots N$ represent the intersection of lines $L_i$ with
the plane with height $z(\lambda)$.

Note that the set of all means $(\bar{x}(\lambda),\bar{y}(\lambda),z(\lambda))$
comprise a line. For the plane at height $z(\lambda)$ that yields the smallest
spread of points $(x^i(\lambda),y^i(\lambda))$ will be the point on that line
which we choose as our answer. (If desired, this mean line between $(\bar{x}(1),
\bar{y}(1),z_+)$ and $(\bar{x}(0),\bar{y}(0),z_-)$ can be computed first, and
the entire bundle rotated so the mean line becomes vertical.)

The two-dimensional spread of the intersection set at a particular $z(\lambda)$
is a symmetric, positive definite, 2x2 covariance matrix:

\[M(\lambda) =
\begin{bmatrix}
 var(x^i(\lambda)) && covar(x^i(\lambda),y^i(\lambda)) \\
  -                && var(y^i(\lambda))
\end{bmatrix}
\]

It can be shown that the covariance of the interpolated points
$(x^i(\lambda), y^i(\lambda))$ can be expressed in terms of variances of and
covariances between the four elementary datasets $x^i_+, x^i_-, y^i_+, y^i_-$ as
follows:

\begin{equation}\label{varx}
var(x^i(\lambda)) = \lambda^2\sigma^2_{x+x+} + \lambda(1-\lambda)(\sigma^2_{x+x-} + \sigma^2_{x-x+}) 
                + (1-\lambda)^2\sigma^2_{x-x-}
\end{equation}
\begin{equation}\label{vary}
var(y^i(\lambda)) = \lambda^2\sigma^2_{y+y+} + \lambda(1-\lambda)(\sigma^2_{y+y-} + \sigma^2_{y-y+}) 
                + (1-\lambda)^2\sigma^2_{y-y-}\end{equation}
\begin{equation}\label{covarxy}
covar(x^i(\lambda),y^i(\lambda)) = \lambda^2\sigma^2_{x+y+}  
                        + \lambda(1-\lambda)(\sigma^2_{x+y-} + \sigma^2_{x-y+}) 
                              + (1-\lambda)^2\sigma^2_{x-y-}
\end{equation}

where
$$\sigma^2_{x+x+}=var(x^i_+),$$
$$\sigma^2_{x+y-}=covar(x^i_+, y^i_-),$$ 
etc. Note in particular that, since all the $\sigma^2$ are functions only of
constants $x^i_\pm, y^i_\pm$, and $N$, each of the 4 elements of $M(\lambda)$ is
a quadratic function of $\lambda$.

If we denote the determinant of a matrix with $|\cdot|$, the area of the
1-sigma error ellipse of $M(\lambda)$ is
$$a(\lambda) = \pi\sqrt{|M(\lambda)|},$$
i.e. the square root of a quartic (4th degree) polynomial.

We seek to minimize $a(\lambda)$, which is equivalent to minimizing
the quartic polynomial 
\begin{eqnarray*}
d(\lambda)&=&|M(\lambda)| \\
          &=&var(x^i(\lambda))var(y^i(\lambda)) - covar(x^i(\lambda),y^i(\lambda))^2
\end{eqnarray*}

Note that, for efficient computation, the quadratic, linear, and
constant coefficients of equations (\ref{varx}-\ref{covarxy}) can be
computed to restate more simply as:
\begin{equation}\label{qx}
var(x^i(\lambda)) = a_x\lambda^2 + b_x\lambda + c_x
\end{equation}
\begin{equation}\label{qy}
var(y^i(\lambda)) = a_y\lambda^2 + b_y\lambda + c_y
\end{equation}
\begin{equation}\label{qxy}
covar(x^i(\lambda),y^i(\lambda)) = a_{xy}\lambda^2 + b_{xy}\lambda + c_{xy}
\end{equation}

Given coefficients computed in equations (\ref{qx}-\ref{qxy}),
$d(\lambda)$ can then be expressed as
\begin{eqnarray}\label{d}
d(\lambda) &=& (a_x\lambda^2 + b_x\lambda + c_x)(a_y\lambda^2 + b_y\lambda + c_y) - 
(a_{xy}\lambda^2 + b_{xy}\lambda + c_{xy})^2 \nonumber \\
&=& (a_xa_y-a_{xy}^2)\lambda^4 + (a_xb_y+b_za_y-2a_{xy}b_{xy})\lambda^3 + \nonumber \\
&& (a_xc_y+b_xb_y+c_xa_y-2a_{xy}c_{xy}-b^2_{xy})\lambda^2 +\\
&& (b_xc_y+c_xb_y-2b_{xy}c_{xy})\lambda + (c_xc_y-c^2_{xy}) \nonumber
\end{eqnarray}

The value $\lambda_{min}$ which minimizes $d(\lambda)$ will also determine the
height $z(\lambda_{min})$ of the output ground point, and then $\lambda_{min}$
can be used to interpolate the intersection set
$(x^i(\lambda_{min}), y^i(\lambda_{min}))$, of which the mean
$(\bar{x}(\lambda_{min}), \bar{y}(\lambda_{min}))$ constitutes the horizontal
component of the output ground point.

\subsection{Empirical Equivalence with MIG}
For every MIG calculation that went into Figures
\ref{fig:vanillaref}--\ref{fig:vanilla_pred_meas}, an Hourglass geolocation
calculation was also performed. Figure \ref{fig:mig_vs_hourglass} shows the
actual errors in the X, Y, and Z directions from a MIG calculation (horizontal
axis) versus an Hourglass calculation (vertical axis), for all of those
calculations. The scatter follows the unity line $y=x$ very closely, showing
that Hourglassing yields very closely the same geolocation as MIG.

\begin{figure}
\includegraphics[width=.8\textwidth]{fig_mig_ply_xyz_sma.png}
\includegraphics[width=.8\textwidth]{fig_mig_ply_xyz_big.png}
\caption{\label{fig:mig_vs_hourglass}MIG vs Hourglass errors. All scales are
  meters. Each row is one graph each for X, Y, and Z errors. Above, 700 points
  are plotted from intersections with $4\le N\le 100$. Below, 26900 points are
  plotted for $10<N<1000$.}
\end{figure}


\subsection{Non-uniqueness}
It is desirable that this quartic polynomial $d(\lambda)$ have no
local minima, but only a single, global minimum. Equivalently, the
cubic derivative should have a single real root and two complex
roots. Unfortunately, there can be degenerate arrangements of image
rays with three real roots of $d'(\lambda$) and multiple minima for
$d(\lambda)$.

%% Consider the following bimodal situation: images of a ground area are captured
%% from satellite positions spaced equally around a horizontal circle, with
%% orientations perfectly intersecting at a ground point at height $z_+$. To this
%% bundle add a duplicate bundle, shifted both horizontally and downwards, to
%% intersect at a lower height $z_-$. Clearly, the spread of the joint bundle at
%% heights $z(\lambda=0)=z_-$ and $z(\lambda=1)=z_+$ are the same. And the spread
%% at $z(\lambda=1/2)$ is somewhat larger (note that the shape of $d(\lambda)$ is
%% depicted sideways to the right). Thus $\lambda={0,1}$ present two minima of
%% $d(\lambda)$, and the hourglassing procedure in this case cannot provide a clear
%% answer.

At least we can compute the exact form of $d(\lambda)$, and with standard
techniques understand clearly whether such a degenerate situation were ever to
present itself. In our empirical testing in section \ref{hsimulation}, we very
seldom encountered such a degenerate case. In the 27600 Hourglassing
computations, 26 degenerate cases were encountered: 16 for $N=4$, 7 for $N=5$,
and 1 each for $N=6,7,8$. In each case, the outer two extrema are local minima,
and the middle is a local maximum, and the ambiguity of the degeneracy was
computed as the difference between the local minimum values of $d(\lambda)$. The
ambiguities ranged from 0.15 to 65. In any case, these are very small numbers of
images, within the scope of this study. Numbers as small as $N=4$ were included
only to provide context and continuity to the results for large numbers of
images. As demonstrated by this study, the chance of degeneracy for a large
number of images is negligible, and in any case it can be detected for manual
review.


\subsection{Error Estimation}
Review of Figures \ref{fig:vanilla_pred_meas}--\ref{fig:vanilla_pred_meas_sqrtn}
suggests an empirical meth\-od of error estimation for Hourglassing. Predicted
error decreases very predictably as $1/\sqrt N$. So an alternative method for
estimating the error of a MIG with $N$ images would be to subsample $M \ll N$
images many times, compute the sample covariance $C_M$ of the $M$-MIGs, and
because of the $1/\sqrt N$ behavior (which is $1/N$ in variance space), and
using a finite population correction, predict the error of the $N$-MIG to
be $$C_N=C_M\frac{M}{N}\cdot\frac{N-1}{N-M}$$

This allows estimation of error apart from the output covariance of the $N$-MIG
(or even of any of the $M$-MIG). There's not much point to this for MIG, since
output covariance is a natural by-product of the MIG algorithm. But for
Hourglassing, this provides a method of error estimation which requires no
apriori error information, simply calculation of additional, smaller Hourglass
calculations on many subsamples, and computation and scaling of the sample
covariance of the resulting set of geolocations.

The fundamental principle behind this error estimation technique, is that
apriori error information is not needed for each image in the bundle, because
the bundle {\em is} the distribution of error. For typical collections of only 2
or 4 images, the sample size is too small to reliably know whether the ray
separation is a true representation of the amount of error in the system, or
whether it may be concidentally large (or small). Thus a traditional MIG with
apriori and aposteriori covariance, and reference variance as a consistency
check, is most appropriate. But for large enough collections of images, the
distribution of image rays is a reliable summary of the error of the process.

\subsection{\label{hsimulation}Error Estimation Simulated Results}
To evaluate this empirical method of error estimation for Hourglassing, a subset
of $N=100$ images from $\Pimg$ were chosen, and an Hourglass-geolocation
computed for them. Subsets of $M=N/4$ were sampled from the $N$-set, $k=100$
times, and an Hourglass-geolocation is computed for each $M$-subset. 3x3 sample
covariance was computed for those $k$ ground points, and then scaled by
$1/(N/M)=M/N$ because of the $1/\sqrt{N}$ effect, and corrected also by a FPC
factor of $(N-1)/(N-M)$, to yield the covariance estimate for the
$N$-Hourglass. A MIG was also computed for the same $N$-subset, and its output
covariance computed for reference. This experiment was repeated $R=100$ times.

Figure \ref{fig:mig_vs_hourglass_var} shows the variance of X from MIG vs
Hourglass error estimation. The Hourglass error estimation has more spread than MIG.

\begin{figure}
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1.2\linewidth]{fig_self_var_xy.png}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1.2\linewidth]{fig_self_var_z.png}
\end{subfigure}
\caption{\label{fig:mig_vs_hourglass_var}MIG vs Hourglass estimated
  variances. From left to right, the clusters represent $N=$400, 200 and 100
  images.}
\end{figure}

\section{Conclusion}
In conclusion, we conclude.





\begin{thebibliography}{99} % 2-digit reference nums

\bibitem{MANUAL}ASPRS, 20xx {\em Manual of Photogrammetry}, 9th ed., pp ??.

\bibitem{LLN} Casella, George, Roger L. Berger, 1990. {\em Statistical
  Inference}, Brooks/Cole, Belmont CA, pp. 214-20.

\bibitem{PLANE_COLLINS}Collins, R.~T., 1996. A space-sweep approach to true
  multi-image matching, In: {\em Proc. CVPR}, 1996.
% https://www.ri.cmu.edu/pub_files/pub1/collins_robert_1996_1/collins_robert_1996_1.pdf

\bibitem{LRO_NINE}Di, K., B.~Xu, B.~Liu, M.~Jia, Z.~Liu, 2016. Geopositioning
  precision analysis of multiple image triangulation using LRO NAC Lunar
  Images, In: {\em Proc. ISPRS}, 2016.
% http://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLI-B4/369/2016/isprs-archives-XLI-B4-369-2016.pdf

\bibitem{BROWSE_DG}Digital Globe Image Finder, {\tt
  http://browse.digitalglobe.com}, accessed 2017-02-24.

\bibitem{MIN}Dolloff, John, and Reuben Settergren, 2010. Worldview-1 Stereo
  Extraction Accuracy With and Without MIN Processing, In: {\em Proc. ASPRS}, 2010.

\bibitem{PHOTO_CV}F\"orstner, Wolfgang, and Bernhard P.~Wrobel, 2016. {\em
  Photogrammetric Computer Vision}, Springer.

\bibitem{GITHUB} {\tt
  https://github.com/sethmerickel/Multi-Image-Geopositioning}. The
  implementation of Hourglassing described in section \ref{poly} is available,
  as well as sample data.

\bibitem{H_AND_J}Horn, Roger, and Charles R. Johnson, 2012. {\em Matrix
  Analysis}, 2nd ed. Cambridge University Press, p. NNN?

\bibitem{JEONG_SIX}Jeong, Jaehoon, Chansu Yang, Taejung Kim, 2015. Geo-positioning
  accuracy using multiple-satellite images: IKONOS, QuickBird, and KOMPSAT-2
  Stereo Images, {\em Remote Sensing} 7(4), pp.~4549-64.
% http://www.mdpi.com/2072-4292/7/4/4549

\bibitem{LSQRMIG}Mikhail, Edward M., James S.~Bethel, J.~Chris McGlone,
  2001. {\em Modern Photogrammetry}, Wiley, New York.

\bibitem{SGXP}SOCET GXP, {\tt http://geospatialexploitationproducts.com}

\bibitem{FRESNO}Settergren, Reuben, Seth Merickel and Stewart Walker, Title?
  Available online \cite{GITHUB}

\bibitem{PLANE_SWEEP}Szeliski, Richard, 2011. {\em Computer Vision}, Springer,
  London, p. 474.

\bibitem{FPC}Thompson, Steven K., 2012. {\em Sampling}, 3rd ed. Wiley, Hoboken,
  p. 15.

\bibitem{WONNACOT_32_3}Wonnacot, W.~M., 2008. {\em Geolocation with Error Analysis
  Using Imagery from an Experimental Spotlight SAR}, PhD Thesis, Purdue.
% 32 SAR image ``sets'', each a ``three-aperture path sequence''


\end{thebibliography}
 
\end{document}
